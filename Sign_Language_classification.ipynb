{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Sign Language classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1m5fUUufv_-roXcK-R790FndLGsET8qiL",
      "authorship_tag": "ABX9TyPEwvUjtSVWKRGMzg+Hxoz4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lilyaYAHIAOUI/Sign-Language-Classification/blob/main/Sign_Language_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pvjqPN6F7GA4"
      },
      "source": [
        "import urllib.request\n",
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "import tensorflow as tf\n",
        "from shutil import copyfile\n",
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FuYULLw7OFC"
      },
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKxWNpym7JWW"
      },
      "source": [
        "IMAGE_DIR = \"/content/drive/MyDrive/competition/Zindi/Sign Language classification/data/Images\"\n",
        "IMAGE_TEST_DIR = \"/content/drive/MyDrive/competition/Zindi/Sign Language classification/data/Test\"\n",
        "IMAGE_TRAIN_DIR = \"/content/drive/MyDrive/competition/Zindi/Sign Language classification/data/final_data\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrnkNDxs7QVB"
      },
      "source": [
        "df_train = pd.read_csv(\"/content/drive/MyDrive/competition/Zindi/Sign Language classification/data/Train.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/competition/Zindi/Sign Language classification/data/Test.csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpLnAdU47ScN",
        "outputId": "c47b658c-809a-4280-cfa4-47c039157ece"
      },
      "source": [
        "print(\"Number of training images\", df_train.shape[0])\n",
        "print(\"Number of testing images\", df_test.shape[0])\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training images 6249\n",
            "Number of testing images 2679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ih1F-yvB7YZZ",
        "outputId": "ee67f55e-d6ae-4455-8e0e-33678829359e"
      },
      "source": [
        "df_train.columns"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['img_IDS', 'Label'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p237E4bb7Z5H",
        "outputId": "47056095-17e0-47c4-e902-d2301c3db5ad"
      },
      "source": [
        "df_train[\"Label\"].unique()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Temple', 'Church', 'Enough/Satisfied', 'Me', 'Love', 'Mosque',\n",
              "       'You', 'Friend', 'Seat'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZnIh10B7cLX",
        "outputId": "1a743601-d725-4c8f-8d77-1406b738c9b7"
      },
      "source": [
        "print(df_train[\"Label\"].nunique())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc1rbkUu7ifA"
      },
      "source": [
        "# Process Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HirAxLGp7dxU",
        "outputId": "d15d8e0e-4a40-4b72-ff97-a3c6e9766811"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.1,\n",
        "      height_shift_range=0.1,\n",
        "      brightness_range=[0.2,1.0],\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest',\n",
        "      validation_split=0.2 )\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(IMAGE_TRAIN_DIR,\n",
        "                                                    batch_size=30,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    target_size=(224,224),\n",
        "                                                    shuffle=True)\n",
        "\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(IMAGE_TRAIN_DIR,\n",
        "                                                    batch_size=30,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    target_size=(224,224),\n",
        "                                                    shuffle=True,\n",
        "                                                    subset=\"validation\",\n",
        "                                                    )\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6255 images belonging to 9 classes.\n",
            "Found 1246 images belonging to 9 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ABceSWVn7o04"
      },
      "source": [
        "def preprocess_image_input(input_images):\n",
        "  input_images = input_images.astype('float32')\n",
        "  output_ims = tf.keras.applications.resnet50.preprocess_input(input_images)\n",
        "  return output_ims\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1m9suUGk7zyO",
        "outputId": "a065d32a-a17e-4355-95e4-134a2edd0bf0"
      },
      "source": [
        "'''\n",
        "Feature Extraction is performed by ResNet50 pretrained on imagenet weights. \n",
        "Input size is 224 x 224.\n",
        "'''\n",
        "def feature_extractor(inputs):\n",
        "\n",
        "  feature_extractor = tf.keras.applications.resnet.ResNet50(input_shape=(224, 224, 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')(inputs)\n",
        "  return feature_extractor\n",
        "\n",
        "\n",
        "'''\n",
        "Defines final dense layers and subsequent softmax layer for classification.\n",
        "'''\n",
        "def classifier(inputs):\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dense(9, activation=\"softmax\", name=\"classification\")(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def final_model(inputs):\n",
        "\n",
        "\n",
        "    resnet_feature_extractor = feature_extractor(inputs)\n",
        "    classification_output = classifier(resnet_feature_extractor)\n",
        "\n",
        "    return classification_output\n",
        "\n",
        "\n",
        "def define_compile_model():\n",
        "  inputs = tf.keras.layers.Input(shape=(224,224,3))\n",
        "  \n",
        "  classification_output = final_model(inputs) \n",
        "  model = tf.keras.Model(inputs=inputs, outputs = classification_output)\n",
        " \n",
        "  # compile the model\n",
        "  model.compile(optimizer=RMSprop(lr=0.0001),\n",
        "              loss= tf.keras.losses.CategoricalCrossentropy() ,\n",
        "              metrics=['acc'])\n",
        "\n",
        "  return model\n",
        "\n",
        "\n",
        "model = define_compile_model()\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, 7, 7, 2048)        23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              2098176   \n",
            "                                                                 \n",
            " classification (Dense)      (None, 9)                 9225      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,695,113\n",
            "Trainable params: 25,641,993\n",
            "Non-trainable params: 53,120\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u8J92AV47289",
        "outputId": "4f1faff5-87b9-4b2d-9cbf-187f2990d130"
      },
      "source": [
        "EPOCHS = 15\n",
        "checkpoint = ModelCheckpoint(\"/content/drive/MyDrive/competition/Zindi/Sign Language classification/data/model_weights2.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint] \n",
        "\n",
        "history = model.fit(train_generator,validation_data =validation_generator, epochs=EPOCHS, callbacks=callbacks_list)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "209/209 [==============================] - ETA: 0s - loss: 0.8369 - acc: 0.7202\n",
            "Epoch 00001: val_loss improved from inf to 2.54562, saving model to /content/drive/MyDrive/competition/Zindi/Sign Language classification/data/model_weights.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r209/209 [==============================] - 304s 1s/step - loss: 0.8369 - acc: 0.7202 - val_loss: 2.5456 - val_acc: 0.1108\n",
            "Epoch 2/15\n",
            " 28/209 [===>..........................] - ETA: 3:31 - loss: 0.4720 - acc: 0.8452"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-13-c1bad98ef839>\", line 5, in <module>\n",
            "    history = model.fit(train_generator,validation_data =validation_generator, epochs=EPOCHS, callbacks=callbacks_list)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1216, in fit\n",
            "    tmp_logs = self.train_function(iterator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\", line 150, in error_handler\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 910, in __call__\n",
            "    result = self._call(*args, **kwds)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\", line 942, in _call\n",
            "    return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 3131, in __call__\n",
            "    filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 1960, in _call_flat\n",
            "    ctx, args, cancellation_manager=cancellation_manager))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\", line 603, in call\n",
            "    ctx=ctx)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\n",
            "    inputs, attrs, num_outputs)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 742, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 395, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
            "    if not islink(newpath):\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 171, in islink\n",
            "    st = os.lstat(path)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0VNwEJIPCky"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj7y_3Mz9ovA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fc60d0c-735a-4141-e40c-2f0ff13d32d1"
      },
      "source": [
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "test_generator =  test_datagen.flow_from_directory( IMAGE_TEST_DIR,\n",
        "                                                    shuffle=False,\n",
        "                                                          batch_size  = 20,\n",
        "                                                          class_mode  = None, \n",
        "                                                          target_size = (224, 224))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2679 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO6roPhhCOdL"
      },
      "source": [
        "test_generator.reset()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p21Y26o3CQOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46892c54-74e9-4e4c-c502-2f33677741dd"
      },
      "source": [
        "pred = model.predict_generator(test_generator)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWQN5P7vCR0Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "372864d3-5ebc-43d2-d39c-926b2c017c4c"
      },
      "source": [
        "print(pred.shape)\n",
        "filenames=test_generator.filenames\n",
        "print(len(filenames))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2679, 9)\n",
            "2679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N6vT9MzL1Co"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMrTNHbYCTGj"
      },
      "source": [
        "res1 = list(map(lambda st: str.replace(st, \"test/\", \"\"), filenames))\n",
        "res2 = list(map(lambda st: str.replace(st, \".jpg\", \"\"), res1))\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CgjpZ3QCUlU"
      },
      "source": [
        "actual = train_generator.classes\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLcI6ToHMsY6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d70d1abd-5068-4ea9-d759-b889d7ad85ac"
      },
      "source": [
        "type(pred)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tat9HembMuBb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38103e3f-bc67-4a22-b208-e4cd17fbe411"
      },
      "source": [
        "print(pred.shape)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2679, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rzec0KWCVz-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "outputId": "3c22c2d2-fdc6-443c-c8bb-8f5664816894"
      },
      "source": [
        "import os\n",
        "submission = pd.DataFrame()\n",
        "submission[\"ID\"] = res2\n",
        "classes = [\"Church\",\"Enough/Satisfied\",\"Friend\",\"Love\",\"Me\",\"Mosque\",\"Seat\",\"Temple\",\"You\"]\n",
        "for i, c in enumerate(classes):\n",
        "  print(c)\n",
        "  print(i)\n",
        "  submission[c] = pred[:,i]\n",
        "submission.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Church\n",
            "0\n",
            "Enough/Satisfied\n",
            "1\n",
            "Friend\n",
            "2\n",
            "Love\n",
            "3\n",
            "Me\n",
            "4\n",
            "Mosque\n",
            "5\n",
            "Seat\n",
            "6\n",
            "Temple\n",
            "7\n",
            "You\n",
            "8\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Church</th>\n",
              "      <th>Enough/Satisfied</th>\n",
              "      <th>Friend</th>\n",
              "      <th>Love</th>\n",
              "      <th>Me</th>\n",
              "      <th>Mosque</th>\n",
              "      <th>Seat</th>\n",
              "      <th>Temple</th>\n",
              "      <th>You</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ImageID_00AVE728</td>\n",
              "      <td>1.184770e-13</td>\n",
              "      <td>1.736129e-17</td>\n",
              "      <td>4.802207e-17</td>\n",
              "      <td>1.421103e-21</td>\n",
              "      <td>2.224133e-20</td>\n",
              "      <td>2.472392e-22</td>\n",
              "      <td>1.529363e-21</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>2.524177e-22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ImageID_00CB7YJ2</td>\n",
              "      <td>5.568958e-17</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.236309e-17</td>\n",
              "      <td>1.859063e-20</td>\n",
              "      <td>9.652564e-22</td>\n",
              "      <td>1.281013e-21</td>\n",
              "      <td>5.642227e-21</td>\n",
              "      <td>8.569598e-21</td>\n",
              "      <td>1.425388e-20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ImageID_00HEGX6X</td>\n",
              "      <td>2.731526e-05</td>\n",
              "      <td>7.020454e-06</td>\n",
              "      <td>1.050166e-02</td>\n",
              "      <td>9.894543e-01</td>\n",
              "      <td>5.152945e-06</td>\n",
              "      <td>6.879222e-07</td>\n",
              "      <td>2.434829e-08</td>\n",
              "      <td>9.030932e-09</td>\n",
              "      <td>3.837778e-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ImageID_016X4GBI</td>\n",
              "      <td>1.082680e-07</td>\n",
              "      <td>9.304893e-09</td>\n",
              "      <td>2.456886e-12</td>\n",
              "      <td>6.517807e-12</td>\n",
              "      <td>4.562535e-13</td>\n",
              "      <td>9.999999e-01</td>\n",
              "      <td>2.283030e-13</td>\n",
              "      <td>4.555290e-14</td>\n",
              "      <td>3.810057e-12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ImageID_01ITRYRU</td>\n",
              "      <td>1.410902e-10</td>\n",
              "      <td>1.240785e-06</td>\n",
              "      <td>1.136330e-06</td>\n",
              "      <td>5.601510e-07</td>\n",
              "      <td>1.025994e-10</td>\n",
              "      <td>5.585187e-07</td>\n",
              "      <td>9.999963e-01</td>\n",
              "      <td>4.245483e-09</td>\n",
              "      <td>9.841157e-08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 ID        Church  ...        Temple           You\n",
              "0  ImageID_00AVE728  1.184770e-13  ...  1.000000e+00  2.524177e-22\n",
              "1  ImageID_00CB7YJ2  5.568958e-17  ...  8.569598e-21  1.425388e-20\n",
              "2  ImageID_00HEGX6X  2.731526e-05  ...  9.030932e-09  3.837778e-06\n",
              "3  ImageID_016X4GBI  1.082680e-07  ...  4.555290e-14  3.810057e-12\n",
              "4  ImageID_01ITRYRU  1.410902e-10  ...  4.245483e-09  9.841157e-08\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vqucz_uScpM"
      },
      "source": [
        "submission.to_csv('/content/drive/MyDrive/competition/Zindi/Sign Language classification/data/sub4.csv',index=False)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yvy9q4HqhEEx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aed9816-da23-44a5-db0b-fa179c50f969"
      },
      "source": [
        "submission.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2679, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxC3YkSGiqma",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "8344d16f-bcfe-4797-aa7b-18ffd9a17ff4"
      },
      "source": [
        "submission[submission[\"ID\"]==\"ImageID_J3BM90F2\"]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Church</th>\n",
              "      <th>Enough/Satisfied</th>\n",
              "      <th>Friend</th>\n",
              "      <th>Love</th>\n",
              "      <th>Me</th>\n",
              "      <th>Mosque</th>\n",
              "      <th>Seat</th>\n",
              "      <th>Temple</th>\n",
              "      <th>You</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1420</th>\n",
              "      <td>ImageID_J3BM90F2</td>\n",
              "      <td>2.614250e-12</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.163008e-12</td>\n",
              "      <td>4.476683e-15</td>\n",
              "      <td>2.561795e-15</td>\n",
              "      <td>1.371805e-15</td>\n",
              "      <td>3.146961e-10</td>\n",
              "      <td>9.552415e-15</td>\n",
              "      <td>3.391745e-14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    ID        Church  ...        Temple           You\n",
              "1420  ImageID_J3BM90F2  2.614250e-12  ...  9.552415e-15  3.391745e-14\n",
              "\n",
              "[1 rows x 10 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5mWcr2wjyqz"
      },
      "source": [
        ""
      ],
      "execution_count": 24,
      "outputs": []
    }
  ]
}